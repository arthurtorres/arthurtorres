

<h1> Hey! ðŸ‘‹ I'm Arthur!</h1>

<h3>Junior Data Engineering.</h3>

<p>
  <a href="https://www.linkedin.com/in/arthurbaiao/"><img src="https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white" /></a>&nbsp;&nbsp;&nbsp;&nbsp;
</p>

<h3> Main Projects</h3>



[scrappy_cloudrun](https://github.com/arthurtorres/scrappy_cloudrun)  : Scrappy of some news websites(Prensa,The Hacker News) and make them acessible by a POST call on a know endpoint and store the result on GCP.

                 
In this project the main tools used are python,Docker and the Cloud Run Service on GCP.


The main steps of this project are :  Scrappy the data, create a DockerFile to be used by Cloud run, Run the service on Cloud Run and wait for calls on endpoint.


The info to run the code in GCP are explained on the ReadMe.md file


[analise_INEP](https://github.com/arthurtorres/analise_INEP)  : Collect data of high-level education from INEP and make a analysys of it. The main focus of the analys is the focus of the Quotas ACT and its impact on the participation of  social minorities on high-level education.


In this project the main tools used are jupyter notebook and python


The main phases of this project are : Extraction of the data , Store the data in a Google Drive and Exploratory Data Analys(EDA)


[analise_netflix](https://github.com/arthurtorres/analise_netflix) : Given a dataset avaiable on Kaggle with some information about netflix movies and tv shows, make a analysys of it and give some insights from it. Also make a simple reccomedation system using cosine similarity. The analysys are on portuguese.


In this project the main tools used are jupyter notebook and python

                  
The main phases of this project are : Cleaning the data , Exploratory Data Analys(EDA) and creation of a reccomendation system.

      

                  
